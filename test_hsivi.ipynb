{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# HSIVI Model Evaluation on Colored MNIST\n",
        "\n",
        "This notebook evaluates a trained HSIVI model using FID (Fr√©chet Inception Distance) as the main metric.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import math\n",
        "from pathlib import Path\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision.utils import save_image, make_grid\n",
        "from torchmetrics.image.fid import FrechetInceptionDistance\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Add project root to path\n",
        "sys.path.insert(0, '.')\n",
        "\n",
        "from hsivi_train.config import HSIVIConfig\n",
        "from hsivi_train.hsivi_trainer import HSIVITrainer\n",
        "from utils.dataset_h5 import H5ImagesDataset\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(f\"Using device: {device}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Paths - Update these to match your setup\n",
        "CHECKPOINT_PATH = \"./work_dir/hsivi_colored_mnist/checkpoints/latest.pt\"  # Path to trained HSIVI checkpoint\n",
        "CONFIG_PATH = \"./work_dir/hsivi_colored_mnist/config.json\"  # Path to config (optional)\n",
        "DATA_DIR = \"./data\"  # Path to colored MNIST data\n",
        "\n",
        "# Evaluation settings\n",
        "NUM_FID_SAMPLES = 10000  # Number of samples for FID calculation\n",
        "BATCH_SIZE = 64  # Batch size for generation and FID computation\n",
        "SEED = 42  # Random seed for reproducibility\n",
        "\n",
        "# Set random seed\n",
        "torch.manual_seed(SEED)\n",
        "if torch.cuda.is_available():\n",
        "    torch.cuda.manual_seed_all(SEED)\n",
        "np.random.seed(SEED)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load HSIVI Model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load configuration\n",
        "if os.path.exists(CONFIG_PATH):\n",
        "    config = HSIVIConfig.load(CONFIG_PATH)\n",
        "    print(f\"Loaded config from {CONFIG_PATH}\")\n",
        "else:\n",
        "    print(\"Config not found, using default configuration\")\n",
        "    config = HSIVIConfig()\n",
        "\n",
        "print(f\"\\nConfiguration:\")\n",
        "print(f\"  Image size: {config.image_size}x{config.image_size}\")\n",
        "print(f\"  Channels: {config.channels}\")\n",
        "print(f\"  Discrete steps (NFE+1): {config.n_discrete_steps}\")\n",
        "print(f\"  Phi base dim: {config.phi_base_dim}\")\n",
        "print(f\"  F base dim: {config.f_base_dim}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create trainer and load checkpoint\n",
        "trainer = HSIVITrainer(\n",
        "    config=config,\n",
        "    pretrained_epsilon=None,  # Not needed for sampling\n",
        "    device=device\n",
        ")\n",
        "\n",
        "# Load checkpoint\n",
        "if os.path.exists(CHECKPOINT_PATH):\n",
        "    trainer.load_checkpoint(CHECKPOINT_PATH)\n",
        "    print(f\"\\nLoaded checkpoint from {CHECKPOINT_PATH}\")\n",
        "    print(f\"Checkpoint trained for {trainer.step} steps\")\n",
        "else:\n",
        "    raise FileNotFoundError(f\"Checkpoint not found at {CHECKPOINT_PATH}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Real Data for FID Reference\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load real dataset\n",
        "dataset = H5ImagesDataset(DATA_DIR)\n",
        "print(f\"Dataset size: {len(dataset)} images\")\n",
        "\n",
        "dataloader = DataLoader(\n",
        "    dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=True,\n",
        "    num_workers=4,\n",
        "    pin_memory=True\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate Samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate samples from HSIVI model\n",
        "@torch.no_grad()\n",
        "def generate_samples(trainer, num_samples, batch_size=64):\n",
        "    \"\"\"Generate samples from trained HSIVI model.\"\"\"\n",
        "    trainer.phi_net.eval()\n",
        "    \n",
        "    all_samples = []\n",
        "    num_batches = math.ceil(num_samples / batch_size)\n",
        "    \n",
        "    pbar = tqdm(range(num_batches), desc=\"Generating samples\")\n",
        "    for i in pbar:\n",
        "        curr_batch_size = min(batch_size, num_samples - len(all_samples))\n",
        "        samples = trainer.sample(batch_size=curr_batch_size)\n",
        "        all_samples.append(samples.cpu())\n",
        "    \n",
        "    all_samples = torch.cat(all_samples, dim=0)[:num_samples]\n",
        "    trainer.phi_net.train()\n",
        "    \n",
        "    return all_samples\n",
        "\n",
        "print(f\"Generating {NUM_FID_SAMPLES} samples...\")\n",
        "generated_samples = generate_samples(trainer, NUM_FID_SAMPLES, BATCH_SIZE)\n",
        "print(f\"Generated {len(generated_samples)} samples\")\n",
        "print(f\"Sample shape: {generated_samples.shape}\")\n",
        "print(f\"Sample range: [{generated_samples.min():.3f}, {generated_samples.max():.3f}]\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Visualize Generated Samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize some generated samples\n",
        "def show_samples(samples, title=\"Generated Samples\", nrow=8):\n",
        "    \"\"\"Display a grid of samples.\"\"\"\n",
        "    n_samples = min(64, len(samples))\n",
        "    grid = make_grid(samples[:n_samples], nrow=nrow, padding=2, normalize=False)\n",
        "    \n",
        "    plt.figure(figsize=(12, 12))\n",
        "    plt.imshow(grid.permute(1, 2, 0).numpy())\n",
        "    plt.title(title)\n",
        "    plt.axis('off')\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "show_samples(generated_samples, f\"HSIVI Generated Samples (NFE={config.n_discrete_steps - 1})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Visualize some real samples for comparison\n",
        "real_batch = next(iter(dataloader))\n",
        "show_samples(real_batch, \"Real Colored MNIST Samples\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compute FID Score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def compute_fid(\n",
        "    real_dataloader,\n",
        "    fake_samples,\n",
        "    num_real_samples=10000,\n",
        "    device='cuda'\n",
        "):\n",
        "    \"\"\"\n",
        "    Compute FID between real and generated samples.\n",
        "    \n",
        "    Args:\n",
        "        real_dataloader: DataLoader for real images\n",
        "        fake_samples: Generated samples tensor [N, C, H, W] in range [0, 1]\n",
        "        num_real_samples: Number of real samples to use\n",
        "        device: Device to use\n",
        "    \n",
        "    Returns:\n",
        "        FID score\n",
        "    \"\"\"\n",
        "    # Initialize FID metric\n",
        "    fid = FrechetInceptionDistance(feature=2048, normalize=True).to(device)\n",
        "    \n",
        "    # Process real images\n",
        "    print(\"Processing real images...\")\n",
        "    num_processed = 0\n",
        "    pbar = tqdm(real_dataloader, desc=\"Real images\")\n",
        "    \n",
        "    for batch in pbar:\n",
        "        if isinstance(batch, (list, tuple)):\n",
        "            batch = batch[0]\n",
        "        \n",
        "        # Ensure proper format for FID (uint8, 0-255)\n",
        "        batch = batch.to(device)\n",
        "        if batch.max() <= 1.0:\n",
        "            batch = (batch * 255).clamp(0, 255).to(torch.uint8)\n",
        "        else:\n",
        "            batch = batch.clamp(0, 255).to(torch.uint8)\n",
        "        \n",
        "        fid.update(batch, real=True)\n",
        "        num_processed += batch.shape[0]\n",
        "        \n",
        "        if num_processed >= num_real_samples:\n",
        "            break\n",
        "    \n",
        "    print(f\"Processed {num_processed} real images\")\n",
        "    \n",
        "    # Process fake images\n",
        "    print(\"Processing generated images...\")\n",
        "    fake_samples = fake_samples.to(device)\n",
        "    \n",
        "    # Convert to uint8\n",
        "    if fake_samples.max() <= 1.0:\n",
        "        fake_samples_uint8 = (fake_samples * 255).clamp(0, 255).to(torch.uint8)\n",
        "    else:\n",
        "        fake_samples_uint8 = fake_samples.clamp(0, 255).to(torch.uint8)\n",
        "    \n",
        "    # Process in batches\n",
        "    batch_size = 64\n",
        "    for i in tqdm(range(0, len(fake_samples_uint8), batch_size), desc=\"Generated images\"):\n",
        "        batch = fake_samples_uint8[i:i+batch_size]\n",
        "        fid.update(batch, real=False)\n",
        "    \n",
        "    print(f\"Processed {len(fake_samples)} generated images\")\n",
        "    \n",
        "    # Compute FID\n",
        "    fid_score = fid.compute().item()\n",
        "    \n",
        "    return fid_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compute FID\n",
        "print(f\"\\nComputing FID with {NUM_FID_SAMPLES} samples...\")\n",
        "print(\"=\"*50)\n",
        "\n",
        "fid_score = compute_fid(\n",
        "    real_dataloader=dataloader,\n",
        "    fake_samples=generated_samples,\n",
        "    num_real_samples=NUM_FID_SAMPLES,\n",
        "    device=device\n",
        ")\n",
        "\n",
        "print(\"=\"*50)\n",
        "print(f\"\\nüéØ FID Score: {fid_score:.2f}\")\n",
        "print(f\"   Number of function evaluations (NFE): {config.n_discrete_steps - 1}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compare with Baseline DDPM (Optional)\n",
        "\n",
        "If you have a trained DDPM baseline, compare sampling quality at different NFE.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Optional: Load and compare with baseline DDPM model\n",
        "DDPM_CHECKPOINT = \"./ckpts/model-5.pt\"  # Update path\n",
        "\n",
        "compare_with_baseline = os.path.exists(DDPM_CHECKPOINT)\n",
        "\n",
        "if compare_with_baseline:\n",
        "    from diffusion.ddpm import Unet, GaussianDiffusion\n",
        "    from ema_pytorch import EMA\n",
        "    \n",
        "    # Load DDPM model\n",
        "    ddpm_model = Unet(\n",
        "        dim=64,\n",
        "        dim_mults=(1, 2, 4),\n",
        "        channels=config.channels,\n",
        "        flash_attn=False\n",
        "    )\n",
        "    \n",
        "    ddpm_diffusion = GaussianDiffusion(\n",
        "        ddpm_model,\n",
        "        image_size=config.image_size,\n",
        "        timesteps=1000,\n",
        "        sampling_timesteps=config.n_discrete_steps - 1  # Same NFE as HSIVI\n",
        "    )\n",
        "    \n",
        "    # Load checkpoint\n",
        "    ckpt = torch.load(DDPM_CHECKPOINT, map_location=device, weights_only=True)\n",
        "    \n",
        "    # Load into EMA\n",
        "    ema = EMA(ddpm_diffusion, beta=0.995, update_every=10)\n",
        "    ema.load_state_dict(ckpt['ema'])\n",
        "    ema_model = ema.ema_model.to(device)\n",
        "    ema_model.eval()\n",
        "    \n",
        "    print(f\"Loaded DDPM baseline from {DDPM_CHECKPOINT}\")\n",
        "else:\n",
        "    print(f\"DDPM checkpoint not found at {DDPM_CHECKPOINT}\")\n",
        "    print(\"Skipping baseline comparison\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if compare_with_baseline:\n",
        "    # Generate DDPM samples with same NFE\n",
        "    print(f\"\\nGenerating {NUM_FID_SAMPLES} DDPM samples with NFE={config.n_discrete_steps - 1}...\")\n",
        "    \n",
        "    @torch.no_grad()\n",
        "    def generate_ddpm_samples(model, num_samples, batch_size=64):\n",
        "        model.eval()\n",
        "        all_samples = []\n",
        "        num_batches = math.ceil(num_samples / batch_size)\n",
        "        \n",
        "        for i in tqdm(range(num_batches), desc=\"Generating DDPM samples\"):\n",
        "            curr_batch_size = min(batch_size, num_samples - len(all_samples))\n",
        "            samples = model.sample(batch_size=curr_batch_size)\n",
        "            all_samples.append(samples.cpu())\n",
        "        \n",
        "        return torch.cat(all_samples, dim=0)[:num_samples]\n",
        "    \n",
        "    ddpm_samples = generate_ddpm_samples(ema_model, NUM_FID_SAMPLES, BATCH_SIZE)\n",
        "    print(f\"Generated {len(ddpm_samples)} DDPM samples\")\n",
        "    \n",
        "    # Visualize DDPM samples\n",
        "    show_samples(ddpm_samples, f\"DDPM (DDIM) Samples (NFE={config.n_discrete_steps - 1})\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if compare_with_baseline:\n",
        "    # Compute DDPM FID\n",
        "    print(f\"\\nComputing DDPM FID...\")\n",
        "    \n",
        "    ddpm_fid_score = compute_fid(\n",
        "        real_dataloader=dataloader,\n",
        "        fake_samples=ddpm_samples,\n",
        "        num_real_samples=NUM_FID_SAMPLES,\n",
        "        device=device\n",
        "    )\n",
        "    \n",
        "    print(f\"\\n\" + \"=\"*50)\n",
        "    print(f\"COMPARISON RESULTS (NFE = {config.n_discrete_steps - 1})\")\n",
        "    print(\"=\"*50)\n",
        "    print(f\"  HSIVI FID: {fid_score:.2f}\")\n",
        "    print(f\"  DDPM (DDIM) FID: {ddpm_fid_score:.2f}\")\n",
        "    print(\"=\"*50)\n",
        "    \n",
        "    if fid_score < ddpm_fid_score:\n",
        "        print(f\"  ‚úÖ HSIVI is better by {ddpm_fid_score - fid_score:.2f} FID points\")\n",
        "    else:\n",
        "        print(f\"  DDPM is better by {fid_score - ddpm_fid_score:.2f} FID points\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Results\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save generated samples\n",
        "output_dir = Path(\"./hsivi_evaluation\")\n",
        "output_dir.mkdir(exist_ok=True)\n",
        "\n",
        "# Save sample grid\n",
        "nrow = 8\n",
        "grid = make_grid(generated_samples[:64], nrow=nrow, padding=2)\n",
        "save_image(grid, output_dir / \"hsivi_samples_grid.png\")\n",
        "print(f\"Saved sample grid to {output_dir / 'hsivi_samples_grid.png'}\")\n",
        "\n",
        "# Save individual samples\n",
        "samples_dir = output_dir / \"samples\"\n",
        "samples_dir.mkdir(exist_ok=True)\n",
        "for i, sample in enumerate(generated_samples[:100]):\n",
        "    save_image(sample, samples_dir / f\"sample_{i:04d}.png\")\n",
        "print(f\"Saved 100 individual samples to {samples_dir}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save evaluation results\n",
        "import json\n",
        "\n",
        "results = {\n",
        "    \"model\": \"HSIVI\",\n",
        "    \"checkpoint\": CHECKPOINT_PATH,\n",
        "    \"n_discrete_steps\": config.n_discrete_steps,\n",
        "    \"nfe\": config.n_discrete_steps - 1,\n",
        "    \"num_samples\": NUM_FID_SAMPLES,\n",
        "    \"fid_score\": fid_score,\n",
        "    \"config\": {\n",
        "        \"image_size\": config.image_size,\n",
        "        \"channels\": config.channels,\n",
        "        \"phi_base_dim\": config.phi_base_dim,\n",
        "        \"f_base_dim\": config.f_base_dim,\n",
        "        \"skip_type\": config.skip_type,\n",
        "        \"image_gamma\": config.image_gamma,\n",
        "        \"independent_log_gamma\": config.independent_log_gamma,\n",
        "    }\n",
        "}\n",
        "\n",
        "if compare_with_baseline:\n",
        "    results[\"ddpm_fid_score\"] = ddpm_fid_score\n",
        "\n",
        "with open(output_dir / \"evaluation_results.json\", \"w\") as f:\n",
        "    json.dump(results, f, indent=2)\n",
        "\n",
        "print(f\"\\nSaved evaluation results to {output_dir / 'evaluation_results.json'}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*60)\n",
        "print(\"EVALUATION SUMMARY\")\n",
        "print(\"=\"*60)\n",
        "print(f\"Model: HSIVI\")\n",
        "print(f\"Checkpoint: {CHECKPOINT_PATH}\")\n",
        "print(f\"Training steps: {trainer.step}\")\n",
        "print(f\"Number of Function Evaluations (NFE): {config.n_discrete_steps - 1}\")\n",
        "print(f\"Number of samples for FID: {NUM_FID_SAMPLES}\")\n",
        "print(f\"\\nüéØ FID Score: {fid_score:.2f}\")\n",
        "if compare_with_baseline:\n",
        "    print(f\"üìä DDPM (DDIM) FID at same NFE: {ddpm_fid_score:.2f}\")\n",
        "print(\"=\"*60)\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
