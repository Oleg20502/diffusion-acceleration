{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DEIS Sampling Method Testing\n",
    "\n",
    "This notebook tests the **DEIS (Diffusion Exponential Integrator Sampler)** method using `DEISMultistepScheduler` from the diffusers library.\n",
    "\n",
    "DEIS is a fast high-order solver for diffusion ODEs that can generate high-quality samples with fewer function evaluations.\n",
    "\n",
    "## Hyperparameters tested:\n",
    "- **Number of inference steps** (5, 10, 20, 50, 100)\n",
    "- **Solver order** (1, 2, 3)\n",
    "- **Beta schedule** (linear, scaled_linear, squaredcos_cap_v2)\n",
    "- **Solver type** (logrho, midpoint, heun, bh1, bh2)\n",
    "- **Lower order final** (True, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "\n",
    "from ema_pytorch import EMA\n",
    "from torchvision.utils import make_grid, save_image\n",
    "from diffusers import DEISMultistepScheduler\n",
    "\n",
    "from diffusion.ddpm import Unet, GaussianDiffusion\n",
    "\n",
    "# Set device\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Pretrained Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model configuration (should match training config)\n",
    "IMAGE_SIZE = 28\n",
    "CHANNELS = 3\n",
    "TIMESTEPS = 1000\n",
    "\n",
    "# Initialize model architecture\n",
    "model = Unet(\n",
    "    dim=64,\n",
    "    dim_mults=(1, 2, 4),\n",
    "    flash_attn=False,\n",
    "    channels=CHANNELS\n",
    ")\n",
    "\n",
    "# Create diffusion wrapper (needed for loading checkpoint)\n",
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    timesteps=TIMESTEPS,\n",
    "    sampling_timesteps=250\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/home/admin/miniforge3/envs/dif-accel/lib/python3.11/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU0 NVIDIA GeForce GTX 1080 Ti which is of cuda capability 6.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (7.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n",
      "/data/home/admin/miniforge3/envs/dif-accel/lib/python3.11/site-packages/torch/cuda/__init__.py:304: UserWarning: \n",
      "    Please install PyTorch with a following CUDA\n",
      "    configurations:  12.6 following instructions at\n",
      "    https://pytorch.org/get-started/locally/\n",
      "    \n",
      "  warnings.warn(matched_cuda_warn.format(matched_arches))\n",
      "/data/home/admin/miniforge3/envs/dif-accel/lib/python3.11/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU1 NVIDIA GeForce GTX 1080 Ti which is of cuda capability 6.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (7.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n",
      "/data/home/admin/miniforge3/envs/dif-accel/lib/python3.11/site-packages/torch/cuda/__init__.py:283: UserWarning: \n",
      "    Found GPU2 NVIDIA GeForce GTX 1080 Ti which is of cuda capability 6.1.\n",
      "    Minimum and Maximum cuda capability supported by this version of PyTorch is\n",
      "    (7.0) - (12.0)\n",
      "    \n",
      "  warnings.warn(\n",
      "/data/home/admin/miniforge3/envs/dif-accel/lib/python3.11/site-packages/torch/cuda/__init__.py:326: UserWarning: \n",
      "NVIDIA GeForce GTX 1080 Ti with CUDA capability sm_61 is not compatible with the current PyTorch installation.\n",
      "The current PyTorch install supports CUDA capabilities sm_70 sm_75 sm_80 sm_86 sm_90 sm_100 sm_120.\n",
      "If you want to use the NVIDIA GeForce GTX 1080 Ti GPU with PyTorch, please check the instructions at https://pytorch.org/get-started/locally/\n",
      "\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "AcceleratorError",
     "evalue": "CUDA error: out of memory\nSearch for `cudaErrorMemoryAllocation' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAcceleratorError\u001b[39m                          Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load checkpoint\u001b[39;00m\n\u001b[32m      2\u001b[39m CKPT_PATH = \u001b[33m\"\u001b[39m\u001b[33m./ckpts/model-5.pt\u001b[39m\u001b[33m\"\u001b[39m  \u001b[38;5;66;03m# Update this path to your checkpoint\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m ckpt = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43mCKPT_PATH\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweights_only\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m diffusion.load_state_dict(ckpt[\u001b[33m\"\u001b[39m\u001b[33mmodel\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Setup EMA model\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/home/admin/miniforge3/envs/dif-accel/lib/python3.11/site-packages/torch/serialization.py:1530\u001b[39m, in \u001b[36mload\u001b[39m\u001b[34m(f, map_location, pickle_module, weights_only, mmap, **pickle_load_args)\u001b[39m\n\u001b[32m   1528\u001b[39m             \u001b[38;5;28;01mexcept\u001b[39;00m pickle.UnpicklingError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m   1529\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m pickle.UnpicklingError(_get_wo_message(\u001b[38;5;28mstr\u001b[39m(e))) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1530\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_load\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1531\u001b[39m \u001b[43m            \u001b[49m\u001b[43mopened_zipfile\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1532\u001b[39m \u001b[43m            \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1533\u001b[39m \u001b[43m            \u001b[49m\u001b[43mpickle_module\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1534\u001b[39m \u001b[43m            \u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m=\u001b[49m\u001b[43moverall_storage\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1535\u001b[39m \u001b[43m            \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mpickle_load_args\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1536\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1537\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m mmap:\n\u001b[32m   1538\u001b[39m     f_name = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(f, \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m, \u001b[39m\u001b[33m\"\u001b[39m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/home/admin/miniforge3/envs/dif-accel/lib/python3.11/site-packages/torch/serialization.py:2122\u001b[39m, in \u001b[36m_load\u001b[39m\u001b[34m(zip_file, map_location, pickle_module, pickle_file, overall_storage, **pickle_load_args)\u001b[39m\n\u001b[32m   2120\u001b[39m \u001b[38;5;28;01mglobal\u001b[39;00m _serialization_tls\n\u001b[32m   2121\u001b[39m _serialization_tls.map_location = map_location\n\u001b[32m-> \u001b[39m\u001b[32m2122\u001b[39m result = \u001b[43munpickler\u001b[49m\u001b[43m.\u001b[49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2123\u001b[39m _serialization_tls.map_location = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   2125\u001b[39m torch._utils._validate_loaded_sparse_tensors()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/home/admin/miniforge3/envs/dif-accel/lib/python3.11/site-packages/torch/serialization.py:2086\u001b[39m, in \u001b[36m_load.<locals>.persistent_load\u001b[39m\u001b[34m(saved_id)\u001b[39m\n\u001b[32m   2084\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2085\u001b[39m     nbytes = numel * torch._utils._element_size(dtype)\n\u001b[32m-> \u001b[39m\u001b[32m2086\u001b[39m     typed_storage = \u001b[43mload_tensor\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   2087\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_maybe_decode_ascii\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2088\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2090\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m typed_storage\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/home/admin/miniforge3/envs/dif-accel/lib/python3.11/site-packages/torch/serialization.py:2052\u001b[39m, in \u001b[36m_load.<locals>.load_tensor\u001b[39m\u001b[34m(dtype, numel, key, location)\u001b[39m\n\u001b[32m   2048\u001b[39m \u001b[38;5;66;03m# TODO: Once we decide to break serialization FC, we can\u001b[39;00m\n\u001b[32m   2049\u001b[39m \u001b[38;5;66;03m# stop wrapping with TypedStorage\u001b[39;00m\n\u001b[32m   2051\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch._guards.detect_fake_mode(\u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m2052\u001b[39m     wrap_storage = \u001b[43mrestore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   2053\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   2054\u001b[39m     storage._fake_device = location\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/home/admin/miniforge3/envs/dif-accel/lib/python3.11/site-packages/torch/serialization.py:1859\u001b[39m, in \u001b[36m_get_restore_location.<locals>.restore_location\u001b[39m\u001b[34m(storage, location)\u001b[39m\n\u001b[32m   1858\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mrestore_location\u001b[39m(storage, location):\n\u001b[32m-> \u001b[39m\u001b[32m1859\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdefault_restore_location\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/home/admin/miniforge3/envs/dif-accel/lib/python3.11/site-packages/torch/serialization.py:698\u001b[39m, in \u001b[36mdefault_restore_location\u001b[39m\u001b[34m(storage, location)\u001b[39m\n\u001b[32m    678\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    679\u001b[39m \u001b[33;03mRestores `storage` using a deserializer function registered for the `location`.\u001b[39;00m\n\u001b[32m    680\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    695\u001b[39m \u001b[33;03m       all matching ones return `None`.\u001b[39;00m\n\u001b[32m    696\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    697\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, _, fn \u001b[38;5;129;01min\u001b[39;00m _package_registry:\n\u001b[32m--> \u001b[39m\u001b[32m698\u001b[39m     result = \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlocation\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    699\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    700\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/home/admin/miniforge3/envs/dif-accel/lib/python3.11/site-packages/torch/serialization.py:637\u001b[39m, in \u001b[36m_deserialize\u001b[39m\u001b[34m(backend_name, obj, location)\u001b[39m\n\u001b[32m    635\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m location.startswith(backend_name):\n\u001b[32m    636\u001b[39m     device = _validate_device(location, backend_name)\n\u001b[32m--> \u001b[39m\u001b[32m637\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/home/admin/miniforge3/envs/dif-accel/lib/python3.11/site-packages/torch/storage.py:291\u001b[39m, in \u001b[36m_StorageBase.to\u001b[39m\u001b[34m(self, device, non_blocking)\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(device, torch.device):\n\u001b[32m    290\u001b[39m     device = torch.device(device)\n\u001b[32m--> \u001b[39m\u001b[32m291\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_to\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/data/home/admin/miniforge3/envs/dif-accel/lib/python3.11/site-packages/torch/_utils.py:101\u001b[39m, in \u001b[36m_to\u001b[39m\u001b[34m(self, device, non_blocking)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     98\u001b[39m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.is_sparse, (\n\u001b[32m     99\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33msparse storage is not supported for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdevice.type.upper()\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m tensors\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    100\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     untyped_storage = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mUntypedStorage\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    102\u001b[39m     untyped_storage.copy_(\u001b[38;5;28mself\u001b[39m, non_blocking)\n\u001b[32m    103\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m untyped_storage\n",
      "\u001b[31mAcceleratorError\u001b[39m: CUDA error: out of memory\nSearch for `cudaErrorMemoryAllocation' in https://docs.nvidia.com/cuda/cuda-runtime-api/group__CUDART__TYPES.html for more information.\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "# Load checkpoint\n",
    "CKPT_PATH = \"./ckpts/model-5.pt\"  # Update this path to your checkpoint\n",
    "\n",
    "ckpt = torch.load(CKPT_PATH, map_location=device, weights_only=False)\n",
    "diffusion.load_state_dict(ckpt[\"model\"])\n",
    "\n",
    "# Setup EMA model\n",
    "ema = EMA(diffusion, beta=0.995, update_every=10).to(device)\n",
    "ema.load_state_dict(ckpt[\"ema\"])\n",
    "\n",
    "# Get the EMA model for inference\n",
    "ema_model = ema.ema_model\n",
    "ema_model.eval()\n",
    "\n",
    "# Extract the UNet from the diffusion model\n",
    "unet = ema_model.model\n",
    "unet.eval()\n",
    "\n",
    "print(f\"Model loaded from: {CKPT_PATH}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEIS Sampling Implementation\n",
    "\n",
    "We create a sampling function that uses the `DEISMultistepScheduler` with our trained UNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_deis_scheduler(\n",
    "    num_train_timesteps: int = 1000,\n",
    "    beta_schedule: str = \"scaled_linear\",\n",
    "    beta_start: float = 0.0001,\n",
    "    beta_end: float = 0.02,\n",
    "    solver_order: int = 2,\n",
    "    algorithm_type: str = \"deis\",\n",
    "    solver_type: str = \"logrho\",\n",
    "    lower_order_final: bool = True,\n",
    "):\n",
    "    \"\"\"\n",
    "    Create a DEIS scheduler with specified parameters.\n",
    "    \n",
    "    Args:\n",
    "        num_train_timesteps: Number of training timesteps\n",
    "        beta_schedule: Type of beta schedule ('linear', 'scaled_linear', 'squaredcos_cap_v2')\n",
    "        beta_start: Starting beta value\n",
    "        beta_end: Ending beta value\n",
    "        solver_order: Order of the DEIS solver (1, 2, or 3)\n",
    "        algorithm_type: Algorithm type ('deis' or 'dpmsolver++')\n",
    "        solver_type: Solver type ('logrho', 'midpoint', 'heun', 'bh1', 'bh2')\n",
    "        lower_order_final: Use lower order solver at final steps\n",
    "    \"\"\"\n",
    "    scheduler = DEISMultistepScheduler(\n",
    "        num_train_timesteps=num_train_timesteps,\n",
    "        beta_schedule=beta_schedule,\n",
    "        beta_start=beta_start,\n",
    "        beta_end=beta_end,\n",
    "        solver_order=solver_order,\n",
    "        algorithm_type=algorithm_type,\n",
    "        solver_type=solver_type,\n",
    "        lower_order_final=lower_order_final,\n",
    "        prediction_type=\"epsilon\",  # Our model predicts noise\n",
    "    )\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.inference_mode()\n",
    "def sample_with_deis(\n",
    "    unet,\n",
    "    scheduler,\n",
    "    num_inference_steps: int = 20,\n",
    "    batch_size: int = 16,\n",
    "    image_size: int = 28,\n",
    "    channels: int = 3,\n",
    "    device: str = 'cuda',\n",
    "    return_intermediates: bool = False,\n",
    "):\n",
    "    \"\"\"\n",
    "    Sample images using DEIS scheduler.\n",
    "    \n",
    "    Args:\n",
    "        unet: The denoising UNet model\n",
    "        scheduler: DEIS scheduler instance\n",
    "        num_inference_steps: Number of denoising steps\n",
    "        batch_size: Number of images to generate\n",
    "        image_size: Size of generated images\n",
    "        channels: Number of image channels\n",
    "        device: Device to use\n",
    "        return_intermediates: Whether to return intermediate samples\n",
    "    \n",
    "    Returns:\n",
    "        samples: Generated images (batch_size, channels, image_size, image_size)\n",
    "        intermediates: List of intermediate samples (if return_intermediates=True)\n",
    "        elapsed_time: Time taken for sampling\n",
    "    \"\"\"\n",
    "    # Set number of inference steps\n",
    "    scheduler.set_timesteps(num_inference_steps, device=device)\n",
    "    timesteps = scheduler.timesteps\n",
    "    \n",
    "    # Initialize with random noise\n",
    "    latents = torch.randn(\n",
    "        (batch_size, channels, image_size, image_size),\n",
    "        device=device,\n",
    "        dtype=torch.float32\n",
    "    )\n",
    "    \n",
    "    # Scale initial noise by the scheduler's init_noise_sigma\n",
    "    latents = latents * scheduler.init_noise_sigma\n",
    "    \n",
    "    intermediates = [latents.clone()] if return_intermediates else None\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Denoising loop\n",
    "    for t in tqdm(timesteps, desc=\"DEIS Sampling\", leave=False):\n",
    "        # Create batched timesteps\n",
    "        t_batch = torch.full((batch_size,), t, device=device, dtype=torch.long)\n",
    "        \n",
    "        # Predict noise\n",
    "        noise_pred = unet(latents, t_batch)\n",
    "        \n",
    "        # DEIS step\n",
    "        latents = scheduler.step(noise_pred, t, latents).prev_sample\n",
    "        \n",
    "        if return_intermediates:\n",
    "            intermediates.append(latents.clone())\n",
    "    \n",
    "    elapsed_time = time.time() - start_time\n",
    "    \n",
    "    # Unnormalize from [-1, 1] to [0, 1]\n",
    "    samples = (latents + 1) * 0.5\n",
    "    samples = samples.clamp(0, 1)\n",
    "    \n",
    "    if return_intermediates:\n",
    "        intermediates = [(x + 1) * 0.5 for x in intermediates]\n",
    "        return samples, intermediates, elapsed_time\n",
    "    \n",
    "    return samples, elapsed_time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions for Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_samples(samples, title=\"Generated Samples\", nrow=4, figsize=(10, 10)):\n",
    "    \"\"\"Display a grid of generated samples.\"\"\"\n",
    "    grid = make_grid(samples, nrow=nrow, padding=2, normalize=False)\n",
    "    grid = grid.cpu().permute(1, 2, 0).numpy()\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(grid)\n",
    "    plt.title(title)\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def show_denoising_process(intermediates, num_steps_to_show=8, nrow=8, figsize=(16, 4)):\n",
    "    \"\"\"Visualize the denoising process.\"\"\"\n",
    "    n_intermediates = len(intermediates)\n",
    "    indices = np.linspace(0, n_intermediates - 1, num_steps_to_show, dtype=int)\n",
    "    \n",
    "    selected = [intermediates[i][0:1] for i in indices]  # Take first sample\n",
    "    selected = torch.cat(selected, dim=0)\n",
    "    \n",
    "    grid = make_grid(selected, nrow=nrow, padding=2, normalize=False)\n",
    "    grid = grid.cpu().permute(1, 2, 0).numpy().clip(0, 1)\n",
    "    \n",
    "    plt.figure(figsize=figsize)\n",
    "    plt.imshow(grid)\n",
    "    plt.title(\"Denoising Process (Noise -> Image)\")\n",
    "    plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def compare_results(results_dict, figsize=(16, 12)):\n",
    "    \"\"\"Compare samples from different configurations.\"\"\"\n",
    "    n_configs = len(results_dict)\n",
    "    fig, axes = plt.subplots(n_configs, 1, figsize=figsize)\n",
    "    \n",
    "    if n_configs == 1:\n",
    "        axes = [axes]\n",
    "    \n",
    "    for ax, (name, data) in zip(axes, results_dict.items()):\n",
    "        samples = data['samples'][:8]  # Show first 8 samples\n",
    "        grid = make_grid(samples, nrow=8, padding=2, normalize=False)\n",
    "        grid = grid.cpu().permute(1, 2, 0).numpy()\n",
    "        \n",
    "        ax.imshow(grid)\n",
    "        ax.set_title(f\"{name} | Time: {data['time']:.2f}s\")\n",
    "        ax.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 1: Varying Number of Inference Steps\n",
    "\n",
    "Test how sample quality changes with different numbers of denoising steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different numbers of inference steps\n",
    "step_counts = [5, 10, 20, 50, 100]\n",
    "\n",
    "results_steps = {}\n",
    "\n",
    "for num_steps in step_counts:\n",
    "    print(f\"\\nSampling with {num_steps} steps...\")\n",
    "    \n",
    "    scheduler = create_deis_scheduler(\n",
    "        num_train_timesteps=TIMESTEPS,\n",
    "        solver_order=2,\n",
    "        beta_schedule=\"scaled_linear\",\n",
    "    )\n",
    "    \n",
    "    samples, elapsed = sample_with_deis(\n",
    "        unet=unet,\n",
    "        scheduler=scheduler,\n",
    "        num_inference_steps=num_steps,\n",
    "        batch_size=16,\n",
    "        image_size=IMAGE_SIZE,\n",
    "        channels=CHANNELS,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    results_steps[f\"{num_steps} steps\"] = {\n",
    "        'samples': samples,\n",
    "        'time': elapsed\n",
    "    }\n",
    "    print(f\"  Time: {elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "compare_results(results_steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 2: Varying Solver Order\n",
    "\n",
    "DEIS supports solver orders 1, 2, and 3. Higher orders can be more accurate but may be less stable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different solver orders\n",
    "solver_orders = [1, 2, 3]\n",
    "NUM_STEPS = 20\n",
    "\n",
    "results_orders = {}\n",
    "\n",
    "for order in solver_orders:\n",
    "    print(f\"\\nSampling with solver order {order}...\")\n",
    "    \n",
    "    scheduler = create_deis_scheduler(\n",
    "        num_train_timesteps=TIMESTEPS,\n",
    "        solver_order=order,\n",
    "        beta_schedule=\"scaled_linear\",\n",
    "    )\n",
    "    \n",
    "    samples, elapsed = sample_with_deis(\n",
    "        unet=unet,\n",
    "        scheduler=scheduler,\n",
    "        num_inference_steps=NUM_STEPS,\n",
    "        batch_size=16,\n",
    "        image_size=IMAGE_SIZE,\n",
    "        channels=CHANNELS,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    results_orders[f\"Order {order}\"] = {\n",
    "        'samples': samples,\n",
    "        'time': elapsed\n",
    "    }\n",
    "    print(f\"  Time: {elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "compare_results(results_orders)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 3: Varying Beta Schedule\n",
    "\n",
    "Test different noise schedules: linear, scaled_linear, and squaredcos_cap_v2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different beta schedules\n",
    "beta_schedules = [\"linear\", \"scaled_linear\", \"squaredcos_cap_v2\"]\n",
    "NUM_STEPS = 20\n",
    "\n",
    "results_beta = {}\n",
    "\n",
    "for beta_sched in beta_schedules:\n",
    "    print(f\"\\nSampling with beta_schedule='{beta_sched}'...\")\n",
    "    \n",
    "    scheduler = create_deis_scheduler(\n",
    "        num_train_timesteps=TIMESTEPS,\n",
    "        solver_order=2,\n",
    "        beta_schedule=beta_sched,\n",
    "    )\n",
    "    \n",
    "    samples, elapsed = sample_with_deis(\n",
    "        unet=unet,\n",
    "        scheduler=scheduler,\n",
    "        num_inference_steps=NUM_STEPS,\n",
    "        batch_size=16,\n",
    "        image_size=IMAGE_SIZE,\n",
    "        channels=CHANNELS,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    results_beta[beta_sched] = {\n",
    "        'samples': samples,\n",
    "        'time': elapsed\n",
    "    }\n",
    "    print(f\"  Time: {elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "compare_results(results_beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 4: Varying Solver Type\n",
    "\n",
    "DEIS supports different solver types for polynomial interpolation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test different solver types\n",
    "solver_types = [\"logrho\", \"midpoint\", \"heun\", \"bh1\", \"bh2\"]\n",
    "NUM_STEPS = 20\n",
    "\n",
    "results_solver_type = {}\n",
    "\n",
    "for solver_type in solver_types:\n",
    "    print(f\"\\nSampling with solver_type='{solver_type}'...\")\n",
    "    \n",
    "    try:\n",
    "        scheduler = create_deis_scheduler(\n",
    "            num_train_timesteps=TIMESTEPS,\n",
    "            solver_order=2,\n",
    "            beta_schedule=\"scaled_linear\",\n",
    "            solver_type=solver_type,\n",
    "        )\n",
    "        \n",
    "        samples, elapsed = sample_with_deis(\n",
    "            unet=unet,\n",
    "            scheduler=scheduler,\n",
    "            num_inference_steps=NUM_STEPS,\n",
    "            batch_size=16,\n",
    "            image_size=IMAGE_SIZE,\n",
    "            channels=CHANNELS,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        results_solver_type[solver_type] = {\n",
    "            'samples': samples,\n",
    "            'time': elapsed\n",
    "        }\n",
    "        print(f\"  Time: {elapsed:.2f}s\")\n",
    "    except Exception as e:\n",
    "        print(f\"  Error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "if results_solver_type:\n",
    "    compare_results(results_solver_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 5: Lower Order Final Steps\n",
    "\n",
    "Test the effect of using lower order solver at final denoising steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test lower_order_final setting\n",
    "lower_order_options = [True, False]\n",
    "NUM_STEPS = 20\n",
    "\n",
    "results_lower_order = {}\n",
    "\n",
    "for lower_order in lower_order_options:\n",
    "    print(f\"\\nSampling with lower_order_final={lower_order}...\")\n",
    "    \n",
    "    scheduler = create_deis_scheduler(\n",
    "        num_train_timesteps=TIMESTEPS,\n",
    "        solver_order=3,\n",
    "        beta_schedule=\"scaled_linear\",\n",
    "        lower_order_final=lower_order,\n",
    "    )\n",
    "    \n",
    "    samples, elapsed = sample_with_deis(\n",
    "        unet=unet,\n",
    "        scheduler=scheduler,\n",
    "        num_inference_steps=NUM_STEPS,\n",
    "        batch_size=16,\n",
    "        image_size=IMAGE_SIZE,\n",
    "        channels=CHANNELS,\n",
    "        device=device\n",
    "    )\n",
    "    \n",
    "    results_lower_order[f\"lower_order_final={lower_order}\"] = {\n",
    "        'samples': samples,\n",
    "        'time': elapsed\n",
    "    }\n",
    "    print(f\"  Time: {elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize results\n",
    "compare_results(results_lower_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 6: Visualize Denoising Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate samples with intermediate steps\n",
    "scheduler = create_deis_scheduler(\n",
    "    num_train_timesteps=TIMESTEPS,\n",
    "    solver_order=2,\n",
    "    beta_schedule=\"scaled_linear\",\n",
    ")\n",
    "\n",
    "samples, intermediates, elapsed = sample_with_deis(\n",
    "    unet=unet,\n",
    "    scheduler=scheduler,\n",
    "    num_inference_steps=20,\n",
    "    batch_size=4,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    channels=CHANNELS,\n",
    "    device=device,\n",
    "    return_intermediates=True\n",
    ")\n",
    "\n",
    "print(f\"Sampling time: {elapsed:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize denoising process\n",
    "show_denoising_process(intermediates, num_steps_to_show=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 7: Comparison with Baseline DDIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare DEIS with baseline DDIM sampling from the original model\n",
    "NUM_STEPS = 20\n",
    "\n",
    "# DEIS sampling\n",
    "print(\"Sampling with DEIS...\")\n",
    "scheduler_deis = create_deis_scheduler(\n",
    "    num_train_timesteps=TIMESTEPS,\n",
    "    solver_order=2,\n",
    "    beta_schedule=\"scaled_linear\",\n",
    ")\n",
    "\n",
    "deis_samples, deis_time = sample_with_deis(\n",
    "    unet=unet,\n",
    "    scheduler=scheduler_deis,\n",
    "    num_inference_steps=NUM_STEPS,\n",
    "    batch_size=16,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    channels=CHANNELS,\n",
    "    device=device\n",
    ")\n",
    "print(f\"  DEIS time: {deis_time:.2f}s\")\n",
    "\n",
    "# Original DDIM sampling (from diffusion model)\n",
    "print(\"Sampling with original DDIM...\")\n",
    "ema_model.sampling_timesteps = NUM_STEPS\n",
    "start_time = time.time()\n",
    "with torch.no_grad():\n",
    "    ddim_samples = ema_model.sample(batch_size=16)\n",
    "ddim_time = time.time() - start_time\n",
    "print(f\"  DDIM time: {ddim_time:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "comparison_results = {\n",
    "    f\"DEIS ({NUM_STEPS} steps)\": {'samples': deis_samples, 'time': deis_time},\n",
    "    f\"DDIM ({NUM_STEPS} steps)\": {'samples': ddim_samples, 'time': ddim_time},\n",
    "}\n",
    "\n",
    "compare_results(comparison_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Experiment 8: Speed vs Quality Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comprehensive benchmark\n",
    "step_counts_benchmark = [5, 10, 15, 20, 30, 50]\n",
    "orders_benchmark = [1, 2, 3]\n",
    "\n",
    "benchmark_results = []\n",
    "\n",
    "for order in orders_benchmark:\n",
    "    for num_steps in step_counts_benchmark:\n",
    "        scheduler = create_deis_scheduler(\n",
    "            num_train_timesteps=TIMESTEPS,\n",
    "            solver_order=order,\n",
    "            beta_schedule=\"scaled_linear\",\n",
    "        )\n",
    "        \n",
    "        # Run multiple times for accurate timing\n",
    "        times = []\n",
    "        for _ in range(3):\n",
    "            _, elapsed = sample_with_deis(\n",
    "                unet=unet,\n",
    "                scheduler=scheduler,\n",
    "                num_inference_steps=num_steps,\n",
    "                batch_size=16,\n",
    "                image_size=IMAGE_SIZE,\n",
    "                channels=CHANNELS,\n",
    "                device=device\n",
    "            )\n",
    "            times.append(elapsed)\n",
    "        \n",
    "        avg_time = np.mean(times)\n",
    "        benchmark_results.append({\n",
    "            'order': order,\n",
    "            'steps': num_steps,\n",
    "            'time': avg_time\n",
    "        })\n",
    "        print(f\"Order {order}, {num_steps} steps: {avg_time:.3f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot benchmark results\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.DataFrame(benchmark_results)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "\n",
    "for order in orders_benchmark:\n",
    "    data = df[df['order'] == order]\n",
    "    ax.plot(data['steps'], data['time'], marker='o', label=f'Order {order}')\n",
    "\n",
    "ax.set_xlabel('Number of Steps')\n",
    "ax.set_ylabel('Time (seconds)')\n",
    "ax.set_title('DEIS Sampling Time vs Number of Steps')\n",
    "ax.legend()\n",
    "ax.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Save Best Configuration Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate high-quality samples with optimal configuration\n",
    "OUTPUT_DIR = Path(\"./results/deis_samples\")\n",
    "OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Best configuration (adjust based on experiments)\n",
    "scheduler = create_deis_scheduler(\n",
    "    num_train_timesteps=TIMESTEPS,\n",
    "    solver_order=2,\n",
    "    beta_schedule=\"scaled_linear\",\n",
    "    solver_type=\"logrho\",\n",
    "    lower_order_final=True,\n",
    ")\n",
    "\n",
    "samples, elapsed = sample_with_deis(\n",
    "    unet=unet,\n",
    "    scheduler=scheduler,\n",
    "    num_inference_steps=50,\n",
    "    batch_size=64,\n",
    "    image_size=IMAGE_SIZE,\n",
    "    channels=CHANNELS,\n",
    "    device=device\n",
    ")\n",
    "\n",
    "print(f\"Generated 64 samples in {elapsed:.2f}s\")\n",
    "\n",
    "# Save grid\n",
    "save_image(samples, OUTPUT_DIR / \"deis_samples_grid.png\", nrow=8)\n",
    "print(f\"Saved samples to {OUTPUT_DIR}\")\n",
    "\n",
    "# Show samples\n",
    "show_samples(samples, title=\"DEIS Samples (Order 2, 50 steps)\", nrow=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "Key findings from DEIS experiments:\n",
    "\n",
    "1. **Number of Steps**: More steps generally produce better quality but take longer. DEIS can achieve good quality with 20-50 steps.\n",
    "\n",
    "2. **Solver Order**: Higher order (2 or 3) usually gives better results for a fixed number of steps. Order 2 is a good balance.\n",
    "\n",
    "3. **Beta Schedule**: The schedule should ideally match what was used during training. `scaled_linear` is a common choice.\n",
    "\n",
    "4. **Solver Type**: `logrho` is the default and works well for most cases.\n",
    "\n",
    "5. **Lower Order Final**: Using lower order at final steps can improve stability for high-order solvers."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dif-accel",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
