{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "580f2bdd-5b50-4410-8f56-676ff9d1f382",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5c4b7886-3665-4949-9489-feea68695699",
   "metadata": {},
   "outputs": [],
   "source": [
    "from diffusion.ddpm import Unet, GaussianDiffusion, Trainer\n",
    "\n",
    "model = Unet(\n",
    "    dim = 64,\n",
    "    dim_mults = (1,2,4),\n",
    "    flash_attn = False\n",
    ")\n",
    "\n",
    "diffusion = GaussianDiffusion(\n",
    "    model,\n",
    "    image_size = 28,\n",
    "    timesteps = 1000,          \n",
    "    sampling_timesteps = 250   \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e129947-30b0-48b2-8824-153724035074",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    diffusion,\n",
    "    './data',\n",
    "    train_batch_size = 128,\n",
    "    train_lr = 5e-5,\n",
    "    train_num_steps = 50000,        \n",
    "    gradient_accumulate_every = 1,    \n",
    "    ema_decay = 0.995,             \n",
    "    amp = True,                  \n",
    "    calculate_fid = False,\n",
    "    save_and_sample_every = 10000,\n",
    "    num_fid_samples = 1000, \n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e01913e2-7ebf-4410-b65f-2c256ce7d399",
   "metadata": {},
   "source": [
    "### Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "136b69e7-fd6b-4c28-a714-67dd6cd03d43",
   "metadata": {},
   "source": [
    "### Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfbb69e7-c74f-4c4d-bdfb-9f1e7aff7bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from ema_pytorch import EMA\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "ckpt_path = \"./ckpts/model-5.pt\"  \n",
    "\n",
    "device = 'cuda'\n",
    "\n",
    "ckpt = torch.load(ckpt_path, map_location=device)\n",
    "diffusion.load_state_dict(ckpt[\"model\"])\n",
    "\n",
    "ema = EMA(diffusion, beta=0.995, update_every=10).to(device)\n",
    "\n",
    "ema.load_state_dict(ckpt[\"ema\"])\n",
    "\n",
    "ema_model = ema.ema_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e71f2e96-7a2e-40b6-a5c7-2d9ddb5c2458",
   "metadata": {},
   "outputs": [],
   "source": [
    "ema_model.eval()\n",
    "\n",
    "with torch.no_grad():\n",
    "    samples = ema_model.sample(batch_size=16)  \n",
    "    save_image(samples, \"results/samples_baseline.png\", nrow=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1286bfde-01c9-43f7-9c28-ab2e6aa1b834",
   "metadata": {},
   "source": [
    "Sample 1k imgs for FID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15349fbd-7875-4d9d-9c39-5645d4641286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aacda315-52d0-4206-b6dd-091f49de1327",
   "metadata": {},
   "source": [
    "### FID Calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1de22772-c64b-49fa-9c66-4c8c8b21faf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms as T\n",
    "from PIL import Image\n",
    "\n",
    "from torchmetrics.image.fid import FrechetInceptionDistance\n",
    "\n",
    "\n",
    "class ImageFolderDataset(Dataset):\n",
    "    def __init__(self, root, image_size=299):\n",
    "        self.root = Path(root)\n",
    "        exts = [\".jpg\", \".jpeg\", \".png\", \".bmp\", \".webp\"]\n",
    "        self.paths = sorted(\n",
    "            p for ext in exts for p in self.root.rglob(f\"*{ext}\")\n",
    "        )\n",
    "\n",
    "        if len(self.paths) == 0:\n",
    "            raise RuntimeError(f\"No images found in {self.root}\")\n",
    "\n",
    "        self.transform = T.Compose([\n",
    "            T.ConvertImageDtype(torch.float32),\n",
    "        ])\n",
    "        self.resize = T.Resize((image_size, image_size))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        path = self.paths[idx]\n",
    "        img = Image.open(path).convert(\"RGB\")  \n",
    "        img = self.resize(img)\n",
    "        img = T.functional.to_tensor(img)\n",
    "        return img\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_fid(\n",
    "    real_dir: str,\n",
    "    fake_dir: str,\n",
    "    batch_size: int = 64,\n",
    "    device: str = None,\n",
    "    num_workers: int = 4,\n",
    ") -> float:\n",
    "\n",
    "    if device is None:\n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "    real_ds = ImageFolderDataset(real_dir)\n",
    "    fake_ds = ImageFolderDataset(fake_dir)\n",
    "\n",
    "    real_loader = DataLoader(\n",
    "        real_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "    fake_loader = DataLoader(\n",
    "        fake_ds,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=num_workers,\n",
    "        pin_memory=True,\n",
    "    )\n",
    "\n",
    "    fid = FrechetInceptionDistance(feature=2048).to(device)\n",
    "    fid.eval()\n",
    "\n",
    "    for imgs in real_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        fid.update(imgs, real=True)\n",
    "\n",
    "    for imgs in fake_loader:\n",
    "        imgs = imgs.to(device)\n",
    "        fid.update(imgs, real=False)\n",
    "\n",
    "    value = fid.compute().item()\n",
    "    return value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938e9f8a-40bd-41d1-88e5-5ad2f3c98591",
   "metadata": {},
   "outputs": [],
   "source": [
    "real_path = \"./data/val\"         \n",
    "fake_path = \"./samples/baseline\"  \n",
    "\n",
    "fid_value = compute_fid(real_path, fake_path, batch_size=64)\n",
    "print(f\"FID(real={real_path}, fake={fake_path}) = {fid_value:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
